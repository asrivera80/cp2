# Permitir el tráfico necesario
- name: puertos para nodo master k8
  firewalld:
    port: "{{ item }}"
    permanent: true
    state: enabled
  loop:
    - 6443/tcp
    - 2379-2380/tcp
    - 10250-10252/tcp
    - 10255/tcp
# Permitir conexiones desde los worker
- name: allow access to workers
  firewalld:
    rich_rule: "{{item}}"
    permanent: yes
    immediate: yes
    state: enabled
  loop:
    - 'rule family=ipv4 source address=10.0.1.11/24 accept'
    - 'rule family=ipv4 source address=10.0.1.12/24 accept'
- name: reiniciar servicio firewalld
  systemd: 
    name: firewalld
    state: reloaded
# configuración de kubeadm
- name: Configurando Kubeadmin
  become: true
  command: kubeadm config images pull
# instalar plugin CNI de kubernetes y definir la red de los PODs
- name: Instalar el plugin CNI
  command: 'kubeadm init --pod-network-cidr 192.168.0.0/16'
  register: token_k8_nodes
  ignore_errors: true

# obtenemos y mostramos la información en pantalla del token, este nos servirá para posteriormente poder unir los nodos worker
- name: Mostrando la salida de la ejecución del kubeadm init
  debug:
    msg: "{{ token_k8_nodes.stdout_lines }}"

- name: Extrayendo el hash CRT CA del Master
  shell: openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | sha256sum
  register: cert_out

- name: Limpiando el Hash CRT
  set_fact: 
    cert_hash: "{{ cert_out.stdout | regex_search('^[a-f0-9]{64}') }}"

- name: Mostramos el Hash CRT extraido
  debug:
    msg: "{{ cert_hash }}"

- name: Extrayendo el token del Master en formato JSON
  shell: kubeadm token list -o json
  register: salida_token

- name: limpiar Token
  set_fact: 
    token_hash: "{{ salida_token.stdout | from_json | json_query('token') }}"

- name: Mostramos el Token extraido
  debug:
    msg: "{{ token_hash }}"

# Exportar configuración de kubeadmin
- name: exportar configuracion kubeadmin
  lineinfile:
    dest: "/etc/environment"
    state: present
    regexp: "KUBECONFIG="
    line: " KUBECONFIG=/etc/kubernetes/admin.conf"
 # Autorizar el acceso al cluster
- name: crear directorio /azureuser/.kube
  file:
    path: /home/azureuser/.kube
    mode: 0755
    state: directory
- name: Copiando /etc/kubernetes/admin.conf a /home/azureuser/.kube/config
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /home/azureuser/.kube/config
    remote_src: yes
    owner: azureuser
    group: azureuser
    mode: 0644
- name: comprobar nodos
  command: kubectl get nodes
  register: nodoscluster
- name: Mostrando la salida de los nodos del cluster
  debug:
    msg: "{{ nodoscluster.stdout_lines }}"   
# Installación de Calico
- name: instala calico
  command: kubectl --kubeconfig=/home/azureuser/.kube/config apply -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
#Añadirmos el ingress
- name: add ingress
  command: kubectl apply -f https://raw.githubusercontent.com/haproxytech/kubernetes-ingress/master/deploy/haproxy-ingress.yaml
- name: puertos para el SDN
  firewalld:
    port: "{{ item }}"
    permanent: true
    state: enabled
  loop:
    - 8285/udp
    - 8472/udp
- name: reiniciar servicio firewalld
  systemd: 
    name: firewalld
    state: reloaded
- name: install azure sdn
  shell: kubectl apply -f https://docs.projectcalico.org/manifests/canal.yaml
- name: reinicio del master
  reinicio:
